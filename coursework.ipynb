{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zsRK_xS7pwe"
      },
      "source": [
        "# AI COM2028 COURSEWORK JUPYTER NOTEBOOK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGseJkM_7pwg"
      },
      "source": [
        "#### Overview <br />\n",
        "This coursework concerns the automated classification of images through machine learning techniques. You will work on bloodcell image data, where training samples and their\n",
        "ground truth are provided. You will develop suitable classification techniques to classify\n",
        "unseen examples, a poster to introduce the problem. You will need to submit a Jupyter\n",
        "notebook containing your code for training and evaluation, your prediction outcome of the\n",
        "test dataset, and a poster by 4pm on Wednesday 10th May. Any of your experiment figures\n",
        "and/or tables included in your poster need to be reproducible in the Jupyter notebook that\n",
        "you submit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q89KE6lF7pwh"
      },
      "source": [
        "### Start by importing some relevant modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gm48l4Ij7pwh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMfK3RKi7pwi"
      },
      "source": [
        "# Next load in the training data images (from local machine) <br />\n",
        "# IF USING COLAB, SKIP NEXT TWO CELLS AND USE ONES AFTER IT \n",
        "We can do this using skimage.io <br />\n",
        "We import the imread_collection and concatenate_images functions. <br />\n",
        "These alllow us to read in the images from a given path, and then the concatenate_images function allows us to convert that collection to a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "AFEqqfoY7pwi",
        "outputId": "eec09e7b-1644-47cc-c509-0fe472290cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.io import imread_collection, concatenate_images\n",
        "\n",
        "#set file path for local training images\n",
        "training_images_path = './COM2028_2023/train'\n",
        "\n",
        "#imread_collection allows us to load folder of images into an array\n",
        "training_images_collection = imread_collection(training_images_path + '/*.jpg')\n",
        "training_images = np.concatenate([image[np.newaxis] for image in training_images_collection])\n",
        "print(type(training_images))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFZZ-exw7pwk"
      },
      "source": [
        "# Now we load in the ground truths (labels) (from local machine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JJ2OUOC97pwk"
      },
      "outputs": [],
      "source": [
        "train_groundtruth_path = './COM2028_2023/train.txt'\n",
        "training_image_path_list = []\n",
        "\n",
        "#since we are loading in text (strings) we can use pythons regular file reading functionallity\n",
        "ground_truths = np.array([])\n",
        "\n",
        "def linereader(line):\n",
        "\tvalues = line.split(' ') #each line contains path, value seperated by a space\n",
        "\timage_path = values[0]  #path is 1st value [0]\n",
        "\ttruth = values[1]  #truth is 2nd value [1]\n",
        "\ttruth= truth.strip('\\n') #our value has a '\\n' appended to it for file formatting, we remove this\n",
        "\treturn truth, image_path\n",
        "\n",
        "\n",
        "with open(train_groundtruth_path, 'r') as file:\n",
        "\tfor line in file:\n",
        "\t\ttruth, image_path = linereader(line)\n",
        "\t\tground_truths = np.append(ground_truths, int(truth)) #we add the value to ground_truths array\n",
        "\t\ttraining_image_path_list.append(image_path)\n",
        "\n",
        "\tfile.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uqPWVZ87pwl"
      },
      "source": [
        "# ONLY RUN CELL BELOW IF USING COLAB \n",
        "# THIS CELL HANDLES LOADING OF TRAINING DATA AND ITS ASSOCIATED LABELS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXm9iFO37pwl",
        "outputId": "543beae7-1d0e-4f0f-9119-7e924e2eb360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#ONLY USE IF USING COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!unzip \"drive/MyDrive/COM2028_2023.zip\" -d \"drive/MyDrive\"\n",
        "#DONE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaIiKvw4C0g9",
        "outputId": "b17fed24-b8d8-4b00-c3be-7131bae5cea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List of physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "#check how many GPUs you have on the device\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"List of physical GPUs:\", gpus)\n",
        "print(\"Num GPUs Available: \", len(gpus))\n",
        "if gpus:\n",
        "# Use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "  except:\n",
        "    print('no gpu')\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TIdXfBN7pwl",
        "outputId": "c7d4996a-dd6e-4554-d63c-841f730151b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.io import imread_collection, concatenate_images\n",
        "\n",
        "#set file path for local training images\n",
        "training_images_path = 'drive/MyDrive/COM2028_2023/train'\n",
        "\n",
        "#imread_collection allows us to load folder of images into an array\n",
        "training_images_collection = imread_collection(training_images_path + '/*.jpg')\n",
        "training_images = np.concatenate([image[np.newaxis] for image in training_images_collection])\n",
        "print(type(training_images))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XPyNBqZ_-6o1"
      },
      "outputs": [],
      "source": [
        "#CELL FOR LOADING TARGET VALUES WITH COLAB\n",
        "train_groundtruth_path = 'drive/MyDrive/COM2028_2023/train.txt'\n",
        "training_image_path_list = []\n",
        "\n",
        "#since we are loading in text (strings) we can use pythons regular file reading functionallity\n",
        "ground_truths = np.array([])\n",
        "\n",
        "def linereader(line):\n",
        "\tvalues = line.split(' ') #each line contains path, value seperated by a space\n",
        "\timage_path = values[0]  #path is 1st value [0]\n",
        "\ttruth = values[1]  #truth is 2nd value [1]\n",
        "\ttruth= truth.strip('\\n') #our value has a '\\n' appended to it for file formatting, we remove this\n",
        "\treturn truth, image_path\n",
        "\n",
        "\n",
        "with open(train_groundtruth_path, 'r') as file:\n",
        "\tfor line in file:\n",
        "\t\ttruth, image_path = linereader(line)\n",
        "\t\tground_truths = np.append(ground_truths, int(truth)) #we add the value to ground_truths array\n",
        "\t\ttraining_image_path_list.append(image_path)\n",
        "\n",
        "\tfile.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxXuByg37pwm"
      },
      "source": [
        "# Print out some example images from training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "fqW8oVUB7pwm",
        "outputId": "befa79a4-644e-4988-9b57-84b68261ea91"
      },
      "outputs": [],
      "source": [
        "#print out some example training images\n",
        "#print out 16 example training images using subplots(4,4), giving us 4 rows of 4 columns\n",
        "\n",
        "for i in range(0,16):\n",
        "    plt.subplot(4,4, i+1)\n",
        "    plt.imshow(training_images[i])\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy07y-AA7pwm"
      },
      "source": [
        "# Relevance of colors <br />\n",
        "The above images show three of the blood sample images. <br />\n",
        "Given that the colors of the samples in all images are the same, we can reason that color is potentially meaningless in the process of classifying the images. <br />\n",
        "We should instead focus on the 'shape' of the image, rather than the color. <br />\n",
        "Because of this, we can convert our images to grayscale format. We do this by calculating a weighted sum of the R,G,B values of the images for each image. <br />\n",
        "This is done below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "q2Q03J417pwm",
        "outputId": "860da03b-4008-4d19-8242-4f4af62e177a"
      },
      "outputs": [],
      "source": [
        "#formula for converting images from RGB to grayscale\n",
        "#0.299 R + 0.587 G + 0.114 B\n",
        "\n",
        "#declare an empty numpy array of dimension (1000,28,28) - to store\n",
        "grayscale_training = np.empty((len(training_images),28,28), int)\n",
        "\n",
        "\n",
        "for i in range(0,len(training_images)):\n",
        "\n",
        "    image = training_images[i] \n",
        "    R = image[:,:,0] # [:] means all the points in that direction, in this case zero gets the 1st value (0) in\n",
        "                    #the 3rd dimension, the 2 colons does this for all 256x256 pixels in the image\n",
        "    G = image[:,:,1] #select green colors\n",
        "\n",
        "    B = image[:, :, 2]\n",
        "    gray = 0.299 * R +  0.587*G + 0.114*B\n",
        "\n",
        "    grayscale_training[i] = gray\n",
        "\n",
        "#now we print out grayscale images and their respective original versions\n",
        "\n",
        "\n",
        "for i in range(0,4):\n",
        "    if i<2:\n",
        "        plt.subplot(2, 2,i+1)\n",
        "        plt.imshow(grayscale_training[i], cmap = 'gray')\n",
        "    else:\n",
        "        plt.subplot(2,2, i+1)\n",
        "        plt.imshow(training_images[i-2], cmap = 'gray')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlt5FJ_07pwn",
        "outputId": "48f5e334-312d-41ab-df64-fadfa7a60d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(grayscale_training.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBXfaME77pwn"
      },
      "source": [
        "# Ground truth label values range from 0-7\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j93J2OP57pwo"
      },
      "source": [
        "# Type of classifier to use <br />\n",
        "Since each target can belong to one of 8 classes, we know we need to use a multiclass classifier for our model. <br /> Binary classifier is not suitable here since that only works for samples that can belong to one of two classes. <br />\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN8vhxID7pwo",
        "outputId": "0b65477d-d231-4bbc-dbf0-53cc500902b1"
      },
      "outputs": [],
      "source": [
        "sample1 = training_images[0] #grabs the first training sample\n",
        "print(sample1.shape)\n",
        "\n",
        "plt.imshow(sample1)\n",
        "plt.show()\n",
        "#get top left pixel values\n",
        "topleft_pixels = sample1[0][0]\n",
        "print(topleft_pixels)\n",
        "#then get ~middle pixe values\n",
        "middle_pixels = sample1[14][14]\n",
        "print(middle_pixels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD0VaW6f7pwo"
      },
      "source": [
        "# First model - Multiclass KNN Classifier\n",
        "For the first attempt I am going to use a KNN with the scikit-learn module <br />\n",
        "KNN's are useful for multiclass classification as they allow us to classify images based on similarity to other ones. <br />\n",
        " Despite this, there are a few potential problems with using KNN for this problem\n",
        "1. We have only used KNN with MNIST so far, the dataset for this problem is much larger and the KNN will therefore be more computationally expensive <br />\n",
        "2. KNN can struggle with more complex images, blood sample images are arguably more complex than drawings of images (images for this are 28x28 whereas MNIST has images of size 8x8)\n",
        "\n",
        "For the sake of analysis and testing, I am going to attempt to use a KNN for this classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAEvW5p7pwp"
      },
      "source": [
        "# Defining the KNN Classifier\n",
        "### Before we define the KNN, we need to reshape some of our data\n",
        "- For the input (training data), KNNs can only handle a 2d input (n_samples, sample)\n",
        "- Because of this we need to reformat our input from (8000,28,28) to (8000, 28*28)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ8avfa97pwp"
      },
      "source": [
        "# Splitting our training data into training and validation sets <br />\n",
        "Since our test set is seperate from our training set, we only have to split the data into training/validation split <br />\n",
        "We will now split the grayscale images into training and validation splits of size 80:20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I5WEdv67pwp",
        "outputId": "9ba6447e-a1e0-46cd-959a-db48c82c1de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8000, 784)\n",
            "(2000, 784)\n",
            "(8000, 784)\n",
            "(2000, 784)\n",
            "<class 'numpy.float64'>\n"
          ]
        }
      ],
      "source": [
        "grayscale_training = grayscale_training.reshape(-1, 28*28)\n",
        "sample_size = len(grayscale_training)\n",
        "x_train = grayscale_training[:round(.8*sample_size)]\n",
        "y_train = ground_truths[:round(.8*sample_size)]\n",
        "x_valid = grayscale_training[round(.8*sample_size):]\n",
        "y_valid = ground_truths[round(.8*sample_size):]\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(type(ground_truths[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hBHyVej7pwq"
      },
      "outputs": [],
      "source": [
        "\n",
        "total = 0 \n",
        "for i in range(0,8):\n",
        "    array=[]\n",
        "    for x in ground_truths: \n",
        "        if x == i :\n",
        "            array.append(x)\n",
        "            total += 1 \n",
        "    print(len(array))\n",
        "    print(total)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "E_yKlGp17pwq",
        "outputId": "82fb94a7-b133-457a-f5d0-3a856509ef47"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric='euclidean', n_jobs=-1, weights='distance')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "#we first define the KNN classifier - we start off with N = 4 for nearest neighbours\n",
        "knn_clf = KNeighborsClassifier(n_jobs = -1, weights = 'distance', n_neighbors = 5, metric = 'euclidean')\n",
        "\n",
        "#We then fit out trainig data to the KNN\n",
        "knn_clf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB_6xXkQ7pwq",
        "outputId": "545dd4f7-1480-4709-cfed-fb4d193d514b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.69\n"
          ]
        }
      ],
      "source": [
        "#Now that we've fit our data to the model \n",
        "#We now need to run predictions with our validation data\n",
        "\n",
        "\n",
        "y_knn_pred_valid = knn_clf.predict(x_valid)\n",
        "print(accuracy_score(y_knn_pred_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRYuq38P7pwq"
      },
      "source": [
        "# The initial accuracy score (68.5%) with our validation is not ideal\n",
        "68.5% accuracy against the validation set is not high enough to make the model usable, there are various ways that we can go about addressing this issue.\n",
        "One common way is to tune the hyperparameters of the model - this includes:\n",
        "1. number of n_neighbours - this is the number of neighbours considered when making a prediction\n",
        "2. algorithm - algorithm used when computing the nearest neighbours of a sample\n",
        "3. metric - the distance metric that we use to compute distance between points, this includes Euclidian (straight line), Manhttan (absolute distance) and others\n",
        "\n",
        "## Another thing that we can try is using Cross Validation on our model. \n",
        "Cross validation splits our data into N folds, each time one fold is used for validation and the others are used for training. KNN is prone to overfitting on training data, meaning it performs on unseen (testing) data. Using N fold Cross validation can help to mitigate this issue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFfU_5ts7pwr"
      },
      "source": [
        "# IMPORTANT THING TO REMEMBER WITH CROSS VALIDATION\n",
        "WHEN USING SKLEARN CROSS VALIDATION - WE CAN PLUG IN ENTIRE TRAINING AND LABEL SET, SKLEARN AUTOMATICALLLY SPLITS IT INTO TRAINING AND VALIDATION SETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "radPXJ2s7pwr",
        "outputId": "17ab3308-050e-44b9-949f-4d39f4e12751"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m10\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     score \u001b[39m=\u001b[39m cross_val_score(knn_clf, grayscale_training, ground_truths, cv \u001b[39m=\u001b[39;49m i, n_jobs \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m     score \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mmean() \u001b[39m# take the mean of the cross_val_scores to estimate average performance across the folds\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     scores\u001b[39m.\u001b[39mappend(score)\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
            "File \u001b[1;32mc:\\Users\\liam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Do cross validation with different number of folds\n",
        "#we will try to find the optimal number of folds for cross validation\n",
        "#we will try it with between 2-10 folds\n",
        "\n",
        "scores = []\n",
        "for i in range(2,10):\n",
        "    score = cross_val_score(knn_clf, grayscale_training, ground_truths, cv = i, n_jobs = -1)\n",
        "    score = score.mean() # take the mean of the cross_val_scores to estimate average performance across the folds\n",
        "    scores.append(score)\n",
        "\n",
        "max_val = max(scores)\n",
        "print(max_val)\n",
        "index_val = scores.index(max_val) + 2\n",
        "\n",
        "print(\"Best value for folds: \", index_val)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utk6tP7x7pwr"
      },
      "source": [
        "## Plot number of folds against cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "UVsC0b7h7pwr",
        "outputId": "ddca8e33-cffe-4279-f7fe-10a2546a9696"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "xplt_values = [i for i in range(2, 10)]\n",
        "y_values = scores\n",
        "\n",
        "plt.plot(xplt_values, y_values, 'r-')\n",
        "plt.xlabel(\"Number of folds in CV\")\n",
        "plt.ylabel(\"Cross validation average score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcJs_Z8q7pws"
      },
      "source": [
        "# From the above graph\n",
        "We can see that there is minimal change in the cross_val_score when using folds between 5 and 9 , with the score peaking with 7 folds <br />\n",
        "For this reason we will choose 7 as a good number of folds to use and then go with this to tune the other hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoFivuAb7pws",
        "outputId": "cbee1bfa-39ef-45b3-acd2-3189150f5fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6954004134893986\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "knn_clf = KNeighborsClassifier()\n",
        "score = cross_val_score(knn_clf, grayscale_training, ground_truths, n_jobs = -1, cv=7 ).mean()\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4bjJRlw7pws"
      },
      "source": [
        "## Now we want to find optimal number of n_neighbours\n",
        "This is the number of neighbours each sample considers when being classified as a given target <br />\n",
        "We can do this using GridSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p_u2qRYA7pws"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "hyperparameters = {'n_neighbors': [3,5,7,9,11,13,15]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyspark'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskopt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspark\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkTrials\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
          ]
        }
      ],
      "source": [
        "#TESTING SHIT\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from pyspark.sql import SparkSession\n",
        "from skopt.spark import SparkTrials\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "sr6hxvDn7pws",
        "outputId": "08422c49-2e57-4197-f3ee-588bfe9eb850"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=7, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [3, 5, 7, 9, 11, 13, 15]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=7, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [3, 5, 7, 9, 11, 13, 15]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=7, estimator=KNeighborsClassifier(),\n",
              "             param_grid={'n_neighbors': [3, 5, 7, 9, 11, 13, 15]})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now we run GridSearch to find optimal value for nearest neighbours\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(knn_clf, hyperparameters, cv = 7)\n",
        "grid_search.fit(grayscale_training, ground_truths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t05rUdPq7pwt",
        "outputId": "bc553a9d-a738-43fc-c98a-165b6d8eac74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of this model with  15 is  0.7249012971178674\n"
          ]
        }
      ],
      "source": [
        "#Once we have run that, we have *optimal values for n_neighbours and fold count (cv)\n",
        "optimal_neighbors = grid_search.best_params_['n_neighbors']\n",
        "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_neighbors, weights = 'distance')\n",
        "score = cross_val_score(knn_optimal, grayscale_training, ground_truths, cv = 7).mean()\n",
        "\n",
        "\n",
        "print(\"Accuracy of this model with \",optimal_neighbors, \"is \", score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86t8jzF07pwt"
      },
      "source": [
        "# Progress up to this point\n",
        "So far we have determined an appropriate value for CV folds and N nearest neighbours <br />\n",
        "We have done this using Euclidian (straight line) distance between points for classification <br />\n",
        "Up to this point our model has a validation accuracy of 72%, not great, not terrible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew3jGIgH7pwt"
      },
      "source": [
        "# Running Grid Search with multiple hyperparameters\n",
        "## Our KNN classifier has multiple hyperparameters\n",
        "- Given that each of our hyperparameters has a relatively small range of values, its worth running grid search with all of the hyperparameter options.\n",
        "- By doing this we are guaranteed to find the optimal set of hyperparameters within the defined ranges.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "a7St6kU57pwt",
        "outputId": "43aca1cd-f307-448d-9e4c-614265951822"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ff056a1cce15>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#we will use the same KNN as we used above (knn_clf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_clf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mopt_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    862\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    863\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1869\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mmanhattan_distances\u001b[0;34m(X, Y, sum_over_features)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum_over_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cityblock\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetric_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m             \u001b[0mcdist_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcdist_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m             \u001b[0mmetric_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TEST_METRICS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#First we make a dictionary containing all of the hyper-params as keys and the range of values as their keys\n",
        "param_grid = {\n",
        "    'n_neighbors': [5,7,9,11,13],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean','manhattan','wminkowski'],\n",
        "    'p': [1,2]\n",
        "}\n",
        "\n",
        "#now we call GridSearch with our defined param_grid\n",
        "#we will use the same KNN as we used above (knn_clf)\n",
        "grid_search = GridSearchCV(knn_clf,param_grid=param_grid, cv = 7)\n",
        "grid_search.fit(x_train, y_train)\n",
        "opt_params = grid_search.best_params_\n",
        "\n",
        "n_neighbors_opt = opt_params['n_neighbors']\n",
        "weights_opt = opt_params['weights']\n",
        "metric_opt = opt_params['metric']\n",
        "p_opt = opt_params['p']\n",
        "\n",
        "print(n_neighbors_opt)\n",
        "print(weights_opt)\n",
        "print(metric_opt)\n",
        "print(p_opt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJB9_zqU7pwu",
        "outputId": "abce0232-1b16-4e58-8e1d-cbd30eefb9fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the score for this grid search is  0.7745\n"
          ]
        }
      ],
      "source": [
        "score = grid_search.score(x_valid,y_valid)\n",
        "print('the score for this grid search is ',score)\n",
        "#best params are 13 neighbours, distance weighting, manhattan distance, and p = 1\n",
        "n_neighbors_opt = 13\n",
        "weights_opt = 'distance'\n",
        "metric_opt = 'manhattan'\n",
        "p_opt = 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tKrnSIJk7pwu",
        "outputId": "bde3bc3e-44c3-4bce-aa65-2369fe9931ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7745\n"
          ]
        }
      ],
      "source": [
        "test_clf = KNeighborsClassifier(n_neighbors= 13, weights='distance', metric= 'manhattan', p=1)\n",
        "test_clf.fit(x_train, y_train)\n",
        "print(test_clf.score(x_valid, y_valid))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#best params are 13 neighbours, distance weighting, manhattan distance, and p = 1\n",
        "n_neighbors_opt = 13\n",
        "weights_opt = 'distance'\n",
        "metric_opt = 'manhattan'\n",
        "p_opt = 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrkR4VFS7pwu"
      },
      "source": [
        "# Now run grid search with last two parameters - algorithm and leaf size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uwNyOi0y7pwu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "ball_tree\n"
          ]
        }
      ],
      "source": [
        "#define param grid with above optimised values, add value ranges for the leaf size and algorithm options\n",
        "param_grid_2 = {\n",
        "    'n_neighbors': [n_neighbors_opt],\n",
        "    'weights': [weights_opt],\n",
        "    'metric': [metric_opt],\n",
        "    'p': [p_opt],\n",
        "    'leaf_size': [20,21,22,23],\n",
        "    'algorithm': ['ball_tree', 'kd_tree','brute','auto']\n",
        "}\n",
        "\n",
        "grid_search_2 = GridSearchCV(test_clf, param_grid=param_grid_2, cv = 7)\n",
        "grid_search_2.fit(grayscale_training, ground_truths)\n",
        "opt_leaf_size = grid_search_2.best_params_['leaf_size']\n",
        "opt_algorithm = grid_search_2.best_params_['algorithm']\n",
        "print(opt_leaf_size)\n",
        "print(opt_algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n",
            "manhattan\n",
            "ball_tree\n",
            "20\n",
            "distance\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "#At this point we have 'optimal' values for our KNN classifier\n",
        "print(optimal_neighbors)\n",
        "print(metric_opt)\n",
        "print(opt_algorithm)\n",
        "print(opt_leaf_size)\n",
        "print(weights_opt)\n",
        "print(p_opt)\n",
        "\n",
        "optimal_KNN = KNeighborsClassifier(n_neighbors= optimal_neighbors, metric = metric_opt, algorithm= opt_algorithm, leaf_size=opt_leaf_size, weights= weights_opt, p = p_opt)\n",
        "score = cross_val_score(optimal_KNN, grayscale_training, ground_truths, n_jobs = -1, cv=7 ).mean()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The final score for our KNN is  0.7814005938274541\n"
          ]
        }
      ],
      "source": [
        "print(\"The final score for our KNN is \", score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results of KNN\n",
        "#### At this point we have optimised 6 of the hyperparameters for our KNN, and ended up with a total accuracy of 78% on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JhZjuds7pwu"
      },
      "source": [
        "# Alternative approach for hyper-parameter optimization - Bayesian Search\n",
        "It is useful to optimise multiple hyperparameters for two main reasons:\n",
        "1. Hyperparameters all interact together, an 'optimal' value for one might not be optimal when combined with a different hyperparameter. For this reason its a good idea to optimise hyperparameters simultaneously\n",
        "2. Less code for me to write\n",
        "\n",
        "Despite this, running bayesian optimisation can be rather computationally expensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WfXhNtm7pwv"
      },
      "outputs": [],
      "source": [
        "#Use bayesian search to optimise multiple hyperparameters at once\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer, Categorical\n",
        "\n",
        "\n",
        "#First define the different hyperparameters we want to optimise with a range of values for them\n",
        "#this is done in the format of a dictionary\n",
        "\n",
        "\n",
        "randomstate = np.random.RandomState(seed=42)\n",
        "\n",
        "\n",
        "n_neighbor_vals = [2,3,4,5,6,7,8,9,10,11]\n",
        "n_neighbor_probs = [0.05,0.05,0.05,0.05,0.1,0.1,0.1,0.1,0.2,0.2]\n",
        "n_neighbors = Categorical(categories= n_neighbor_vals, prior = n_neighbor_probs)\n",
        "\n",
        "weight_vals = ['uniform','distance']\n",
        "weight_probs = [0.2,0.8]\n",
        "weights = Categorical(categories=weight_vals, prior = weight_probs)\n",
        "\n",
        "search_spaces = {\n",
        "    'n_neighbors': Categorical(categories=[2,3,4,5,6,7,8,9,10,11], prior = [0.05,0.05,0.05,0.05,0.1,0.1,0.1,0.1,0.2,0.2]),\n",
        "    'weights': Categorical(categories=['uniform','distance'], prior = [0.2,0.8])\n",
        "}\n",
        "\n",
        "\n",
        "#define a KNN instance and perform a Bayesian Search on it with our hyperparam values to be optimized\n",
        "bayesianKNN = KNeighborsClassifier()\n",
        "\n",
        "bayes_optimize = BayesSearchCV(bayesianKNN, search_spaces,  cv = 7, random_state=randomstate)\n",
        "#we need to assign our assumption weightings to the object before fitting our data to it\n",
        "\n",
        "\n",
        "bayes_optimize.fit(x_train, y_train)\n",
        "score = bayes_optimize.score(x_valid,y_valid)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'Best score: {bayes_optimize.best_score_:.3f}')\n",
        "print(f'Best hyperparameters: {bayes_optimize.best_params_}')\n",
        "print(f'Test set score: {score:.3f}')\n",
        "#NEED TO FIX THE PRIOR_DISTRIBUTION NOT BEING ADDED PROPERLY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD05zUO77pwv"
      },
      "source": [
        "# GOOD PAIRS OF HYPERPARAMETERS TO RUN BAYESIAN SEARCH ON \n",
        "1. n_neighbours and weight\n",
        "2. p and metric\n",
        "3. algorithm and leaf size\n",
        "\n",
        "### In the above cell we ran Bayesian Search to find optimal values for the n_neighbors and weights parameters of our KNN model\n",
        "We can run Bayesian search with all of the hyperparameters for our KNN model, but this may be computationally expensive to do so.  <br />\n",
        "Instead we can run Bayesian Search multiple time, but with pairs of the hyperparameters (as listed above), I will do this below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsDZKvwj7pwv"
      },
      "outputs": [],
      "source": [
        "##Run bayesian search with p and metric parameters\n",
        "n_neighbors_opt = bayes_optimize.best_params_['n_neighbors']\n",
        "weights_opt = bayes_optimize.best_params_['weights']\n",
        "print(n_neighbors_opt)\n",
        "print(weights_opt)\n",
        "print('Best params so far are ',n_neighbors_opt, \"neighbours and '\",weights_opt,\"' value for weighting\")\n",
        "\n",
        "prior_distribution = {\n",
        "    'p': Integer(low = 1, high = 2 , prior = 'uniform'),\n",
        "    'metric': Categorical(categories=['manhattan', 'euclidean'], prior = [0.5,0.5]),\n",
        "    'n_neighbors': Categorical(categories = [n_neighbors_opt],  prior = [1]),\n",
        "    'weights': Categorical(categories=[weights_opt], prior = [1])\n",
        "\n",
        "}\n",
        "\n",
        "bayes_optimize2 = BayesSearchCV(bayesianKNN, prior_distribution, cv = 7, random_state = randomstate)\n",
        "\n",
        "bayes_optimize2.fit(x_train, y_train)\n",
        "score = bayes_optimize2.score(x_valid,y_valid)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'Best score: {bayes_optimize2.best_score_:.3f}')\n",
        "print(f'Best hyperparameters: {bayes_optimize2.best_params_}')\n",
        "print(f'Test set score: {score:.3f}')\n",
        "#NEED TO FIX THE PRIOR_DISTRIBUTION NOT BEING ADDED PROPERLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGHsNATr7pwv"
      },
      "outputs": [],
      "source": [
        "#get optimal params from above\n",
        "p_opt = bayes_optimize2.best_params_['p']\n",
        "metric_opt = bayes_optimize2.best_params_['metric']\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kbOS-d5N7pww"
      },
      "source": [
        "# Defining the model (CNN) <br />\n",
        "\n",
        "At this point we have tried using a KNN, optimising parameters with both GridSearch and BayesSearch. These optimisation methods have not yielded great results, and our models accuracy on validation data is not great.  <br />\n",
        "At this point I will move onto using a CNN (Convolutional Neural Network) <br />\n",
        "\n",
        "- We define a few of the hyperparameters such as learning rate, the optimizer we want to use and the loss function of choice\n",
        "- Once these are defined, we then declare out model with Keras.Sequential()\n",
        "- - Once we've done this we add various layers, generally in the order - convolutional -> pooling -> fully connected -> output layer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "O_HcWzu_7pww"
      },
      "outputs": [],
      "source": [
        "#Importing all libraries that are relevant to the creation and training of models\n",
        "#Import relevant libraries\n",
        "from keras.layers import Rescaling\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "from "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKoGJy9w7pww"
      },
      "source": [
        "# Before we use a CNN, we need to format our training data and labels \n",
        "- If we didn't do this then Keras would be unable to properly work on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3sgWeKgB7pww"
      },
      "outputs": [],
      "source": [
        "#Before we use a CNN, we need to encode our target values correctly\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#one hot encode the ground_truths to vectorise them into a shape of (sample_count, target_number)\n",
        "ground_truths = to_categorical(ground_truths, num_classes=8)\n",
        "\n",
        "#We need to reformat the training data to be of shape (sample_count, H, W, Color channels)\n",
        "grayscale_training = grayscale_training.reshape(10000,28, 28 ,1)\n",
        "x_train, x_valid = x_train.reshape(-1, 28, 28), x_valid.reshape(-1, 28, 28)\n",
        "y_train, y_valid = to_categorical(y_train, num_classes = 8), to_categorical(y_valid, num_classes=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 8)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "print(ground_truths.shape)\n",
        "print(grayscale_training.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLyUrjOC7pww"
      },
      "outputs": [],
      "source": [
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "accuracy = keras.metrics.CategoricalAccuracy()\n",
        "crossentropy = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "\n",
        "model1 = keras.Sequential()\n",
        "model1.add(Rescaling(1./255))\n",
        "model1.add(Conv2D(32, kernel_size=(2,2), activation=\"relu\", input_shape=(28,28,1)))\n",
        "model1.add(Conv2D(64, kernel_size=(4,4), activation=\"relu\"))\n",
        "model1.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(32, activation=\"relu\"))\n",
        "model1.add(Dense(8, activation=\"softmax\"))\n",
        "\n",
        "model1.compile(optimizer=optimizer, metrics = [accuracy], loss = crossentropy)\n",
        "\n",
        "\n",
        "history = model1.fit(grayscale_training, ground_truths, validation_data = (x_valid, y_valid), epochs=10, batch_size=32)# Access training loss\n",
        "train_loss = history.history['loss']\n",
        "print('Training Loss:', train_loss)\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHlu9OoQ7pww"
      },
      "source": [
        "## The above model performs very badly, there are various reasons for this such as:\n",
        "= Low epoch number - Having too few epochs for the model can (and has above) resulted in sever underfitting. The model has not been able to learn the underlying patterns of the input images, and needs more iterations in order to do so. Out model is too simple and performs poorly on training and validation data, it would also perform badly on test data (although not shown above).\n",
        "- Generally unoptimised parameters - As this is the first iteration of our Neural network, the hyperparameters are inevitably unoptimised, and our model is performing much worse than it necessarily could.\n",
        "- There are numerous approached we can take in order to optimise the various hyperparameters in our model\n",
        "\n",
        "## One very obvious (and simple change) is to increase the number of epochs.\n",
        "Given the number of input images, and the spatial resolution of them, a good starting epoch number could be somewhere between 30-100, rather than the 10 used above\n",
        "### We will start with running the same model, just with 40 epochs rather than 10. This will result in a longer training time but will hopefully help our model to 'learn' the training data more effectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U__QvHT7pwx"
      },
      "outputs": [],
      "source": [
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "accuracy = keras.metrics.CategoricalAccuracy()\n",
        "crossentropy = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "\n",
        "model1 = keras.Sequential()\n",
        "model1.add(Rescaling(1./255))\n",
        "model1.add(Conv2D(32, kernel_size=(2,2), activation=\"relu\", input_shape=(28,28,1)))\n",
        "model1.add(Conv2D(64, kernel_size=(4,4), activation=\"relu\"))\n",
        "model1.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(32, activation=\"relu\"))\n",
        "model1.add(Dense(8, activation=\"softmax\"))\n",
        "\n",
        "model1.compile(optimizer=optimizer, metrics = [accuracy], loss = crossentropy)\n",
        "\n",
        "\n",
        "history = model1.fit(grayscale_training, ground_truths, validation_split=0.2, epochs=40, batch_size=32)# Access training loss\n",
        "train_loss = history.history['loss']\n",
        "print('Training Loss:', train_loss)\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjh_Xkpx7pwx"
      },
      "source": [
        "![image.png](attachment:image.png)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
